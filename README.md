# ğŸ§  LangChain RAG Q&A App with FastAPI + OpenRouter + HuggingFace + FAISS

This is a simple but powerful **Question-Answering (Q&A)** application that uses:

- ğŸ§  LangChain for chaining LLMs and retrievers
- ğŸ¤– OpenRouter (`mistral-7b-instruct`) as the LLM backend
- ğŸ“š HuggingFace embeddings to embed documents
- ğŸ” FAISS for fast vector search
- âš¡ FastAPI for exposing the `/ask` endpoint
- ğŸ“„ A `.txt` document as your knowledge base

---

## ğŸš€ What It Does

- Upload or modify a `.txt` file with your knowledge
- Ingest and index it using FAISS
- Ask questions via a simple POST API
- Get answers grounded in your own document (RAG: Retrieval-Augmented Generation)

---

## ğŸ“¦ Prerequisites

- Python 3.10+
- A free [OpenRouter](https://openrouter.ai/) API key
- `pip` and virtual environment setup

---

## ğŸ”§ Installation

```bash
git clone https://github.com/your-username/langchain-docs-bot.git
cd langchain-docs-bot

python -m venv venv
source venv/bin/activate   # or venv\Scripts\activate on Windows

pip install -r requirements.txt

## ğŸ”‘ Setup Environment

Create a `.env` file in the root directory:

```ini
OPENROUTER_API_KEY=your_openrouter_api_key_here

## ğŸ“ Add Your Document
Place your .txt file inside the data/ folder:

You can write anything â€” this file is the "brain" for your chatbot.

## ğŸ“¥ Commands to execute ingest file and start server

- python ingest.py
- uvicorn main:app --reload


### âœ… Test the API (Postman or curl)

POST http://localhost:8000/ask
Content-Type: application/json

{
  "question": "What is this document about?"
}

Response

{
  "question": "What is this document about?",
  "answer": "This document discusses artificial intelligence and machine learning.",
  "sources": ["N/A"]
}
